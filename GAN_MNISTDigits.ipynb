{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ef9f394",
   "metadata": {
    "id": "2ef9f394"
   },
   "source": [
    "### Libraries installed in the environment NBP_Course and required by the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b0c08d9",
   "metadata": {
    "id": "9b0c08d9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688e5837",
   "metadata": {
    "id": "688e5837"
   },
   "outputs": [],
   "source": [
    "CUDA = True #change to FALSE if using CPU\n",
    "#DATA_PATH = '~/Data/mnist' #points to the root dircetory of MNIST Dataset. Since I Have not downloded it yet i have passedbelow line\n",
    "DATA_PATH = '.'\n",
    "OUT_PATH = 'output_MNIST'\n",
    "LOG_FILE = os.path.join(OUT_PATH, 'log.txt')\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_CHANNEL = 1 # describes the # of channels of img. (For MINST, it is 1)\n",
    "Z_DIM = 100\n",
    "G_HIDDEN = 64\n",
    "X_DIM = 64\n",
    "D_HIDDEN = 64\n",
    "EPOCH_NUM = 25\n",
    "REAL_LABEL = 1\n",
    "FAKE_LABEL = 0\n",
    "lr = 2e-4\n",
    "seed = 1 #Changing this to NONE will give different results everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b72b9588",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b72b9588",
    "outputId": "dcad3ad3-9a1c-4820-f676-4daab74351f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to output_MNIST\\log.txt\n",
      "\n",
      "PyTorch version: 2.0.0\n",
      "CUDA version: 11.7\n",
      "\n",
      "Random Seed:  1\n",
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Epoch 0 [0/469] loss_D_real: 1.1791 loss_D_fake: 1.0658 loss_G: 2.6006\n",
      "Epoch 0 [100/469] loss_D_real: 0.2985 loss_D_fake: 0.0302 loss_G: 3.1676\n",
      "Epoch 0 [200/469] loss_D_real: 0.1256 loss_D_fake: 0.0424 loss_G: 3.7784\n",
      "Epoch 0 [300/469] loss_D_real: 0.1593 loss_D_fake: 0.3422 loss_G: 4.0030\n",
      "Epoch 0 [400/469] loss_D_real: 0.3951 loss_D_fake: 0.3524 loss_G: 2.4432\n",
      "Epoch 1 [0/469] loss_D_real: 0.0090 loss_D_fake: 1.4385 loss_G: 12.1305\n",
      "Epoch 1 [100/469] loss_D_real: 0.1255 loss_D_fake: 0.1108 loss_G: 2.4747\n",
      "Epoch 1 [200/469] loss_D_real: 0.1008 loss_D_fake: 0.4173 loss_G: 3.2262\n",
      "Epoch 1 [300/469] loss_D_real: 0.5596 loss_D_fake: 0.0752 loss_G: 0.9965\n",
      "Epoch 1 [400/469] loss_D_real: 0.3796 loss_D_fake: 0.0841 loss_G: 2.5181\n",
      "Epoch 2 [0/469] loss_D_real: 0.0520 loss_D_fake: 0.4393 loss_G: 4.8578\n",
      "Epoch 2 [100/469] loss_D_real: 0.0837 loss_D_fake: 0.1412 loss_G: 2.8170\n",
      "Epoch 2 [200/469] loss_D_real: 0.0631 loss_D_fake: 0.4261 loss_G: 3.6873\n",
      "Epoch 2 [300/469] loss_D_real: 0.3275 loss_D_fake: 0.0979 loss_G: 1.4753\n",
      "Epoch 2 [400/469] loss_D_real: 0.3475 loss_D_fake: 0.5969 loss_G: 3.0768\n",
      "Epoch 3 [0/469] loss_D_real: 0.2019 loss_D_fake: 1.0444 loss_G: 2.1292\n",
      "Epoch 3 [100/469] loss_D_real: 0.0482 loss_D_fake: 0.0910 loss_G: 3.9117\n",
      "Epoch 3 [200/469] loss_D_real: 0.0689 loss_D_fake: 0.2667 loss_G: 3.9634\n",
      "Epoch 3 [300/469] loss_D_real: 0.0588 loss_D_fake: 0.2404 loss_G: 3.0915\n",
      "Epoch 3 [400/469] loss_D_real: 0.0154 loss_D_fake: 0.1390 loss_G: 6.3993\n",
      "Epoch 4 [0/469] loss_D_real: 0.5744 loss_D_fake: 0.0165 loss_G: 1.3950\n",
      "Epoch 4 [100/469] loss_D_real: 0.3355 loss_D_fake: 0.1304 loss_G: 2.3013\n",
      "Epoch 4 [200/469] loss_D_real: 0.0623 loss_D_fake: 0.0688 loss_G: 3.9648\n",
      "Epoch 4 [300/469] loss_D_real: 0.0388 loss_D_fake: 0.0608 loss_G: 4.4959\n",
      "Epoch 4 [400/469] loss_D_real: 0.0386 loss_D_fake: 0.2925 loss_G: 3.1218\n",
      "Epoch 5 [0/469] loss_D_real: 0.0529 loss_D_fake: 0.0339 loss_G: 3.7986\n",
      "Epoch 5 [100/469] loss_D_real: 0.0401 loss_D_fake: 0.8266 loss_G: 5.2499\n",
      "Epoch 5 [200/469] loss_D_real: 0.1280 loss_D_fake: 0.2588 loss_G: 3.2907\n",
      "Epoch 5 [300/469] loss_D_real: 0.0323 loss_D_fake: 0.0717 loss_G: 4.5268\n",
      "Epoch 5 [400/469] loss_D_real: 0.0444 loss_D_fake: 0.1872 loss_G: 3.9042\n",
      "Epoch 6 [0/469] loss_D_real: 0.0622 loss_D_fake: 0.0181 loss_G: 4.5155\n",
      "Epoch 6 [100/469] loss_D_real: 0.0852 loss_D_fake: 0.2364 loss_G: 4.4573\n",
      "Epoch 6 [200/469] loss_D_real: 0.2883 loss_D_fake: 0.5378 loss_G: 2.1212\n",
      "Epoch 6 [300/469] loss_D_real: 0.0585 loss_D_fake: 0.2028 loss_G: 4.6455\n",
      "Epoch 6 [400/469] loss_D_real: 0.0304 loss_D_fake: 0.3660 loss_G: 4.4492\n",
      "Epoch 7 [0/469] loss_D_real: 0.0467 loss_D_fake: 0.4593 loss_G: 5.9123\n",
      "Epoch 7 [100/469] loss_D_real: 0.0174 loss_D_fake: 0.0689 loss_G: 4.8740\n",
      "Epoch 7 [200/469] loss_D_real: 0.0604 loss_D_fake: 0.1102 loss_G: 3.9285\n",
      "Epoch 7 [300/469] loss_D_real: 0.2577 loss_D_fake: 0.0697 loss_G: 2.8943\n",
      "Epoch 7 [400/469] loss_D_real: 0.0149 loss_D_fake: 0.0272 loss_G: 4.4791\n",
      "Epoch 8 [0/469] loss_D_real: 0.1826 loss_D_fake: 1.6302 loss_G: 1.7830\n",
      "Epoch 8 [100/469] loss_D_real: 0.2599 loss_D_fake: 0.2620 loss_G: 2.2814\n",
      "Epoch 8 [200/469] loss_D_real: 0.3142 loss_D_fake: 0.3295 loss_G: 2.5374\n",
      "Epoch 8 [300/469] loss_D_real: 0.3453 loss_D_fake: 0.5872 loss_G: 1.7270\n",
      "Epoch 8 [400/469] loss_D_real: 0.1143 loss_D_fake: 0.0205 loss_G: 3.8930\n",
      "Epoch 9 [0/469] loss_D_real: 4.7412 loss_D_fake: 0.0255 loss_G: 1.9261\n",
      "Epoch 9 [100/469] loss_D_real: 0.3488 loss_D_fake: 0.1823 loss_G: 2.3245\n",
      "Epoch 9 [200/469] loss_D_real: 0.0303 loss_D_fake: 0.0420 loss_G: 4.2260\n",
      "Epoch 9 [300/469] loss_D_real: 0.0627 loss_D_fake: 0.7552 loss_G: 3.7320\n",
      "Epoch 9 [400/469] loss_D_real: 0.0737 loss_D_fake: 0.6731 loss_G: 5.2274\n",
      "Epoch 10 [0/469] loss_D_real: 0.0559 loss_D_fake: 0.0952 loss_G: 3.8807\n",
      "Epoch 10 [100/469] loss_D_real: 0.0422 loss_D_fake: 0.0168 loss_G: 4.2586\n",
      "Epoch 10 [200/469] loss_D_real: 0.0604 loss_D_fake: 0.3289 loss_G: 3.4371\n",
      "Epoch 10 [300/469] loss_D_real: 0.2076 loss_D_fake: 0.0276 loss_G: 1.9325\n",
      "Epoch 10 [400/469] loss_D_real: 0.0632 loss_D_fake: 0.1068 loss_G: 3.5543\n",
      "Epoch 11 [0/469] loss_D_real: 0.0716 loss_D_fake: 0.0163 loss_G: 4.0523\n",
      "Epoch 11 [100/469] loss_D_real: 0.0109 loss_D_fake: 0.1351 loss_G: 5.8323\n",
      "Epoch 11 [200/469] loss_D_real: 0.0248 loss_D_fake: 0.0175 loss_G: 4.4672\n",
      "Epoch 11 [300/469] loss_D_real: 0.0106 loss_D_fake: 0.0256 loss_G: 5.0067\n",
      "Epoch 11 [400/469] loss_D_real: 0.0695 loss_D_fake: 0.3301 loss_G: 4.1146\n",
      "Epoch 12 [0/469] loss_D_real: 0.1013 loss_D_fake: 0.1326 loss_G: 4.0823\n",
      "Epoch 12 [100/469] loss_D_real: 0.0119 loss_D_fake: 0.7311 loss_G: 6.3492\n",
      "Epoch 12 [200/469] loss_D_real: 0.4907 loss_D_fake: 0.1447 loss_G: 1.3559\n",
      "Epoch 12 [300/469] loss_D_real: 0.0667 loss_D_fake: 0.1813 loss_G: 3.6635\n",
      "Epoch 12 [400/469] loss_D_real: 0.0213 loss_D_fake: 0.0177 loss_G: 4.4093\n",
      "Epoch 13 [0/469] loss_D_real: 0.1600 loss_D_fake: 0.4226 loss_G: 3.3841\n",
      "Epoch 13 [100/469] loss_D_real: 0.0835 loss_D_fake: 0.1779 loss_G: 3.2385\n",
      "Epoch 13 [200/469] loss_D_real: 0.0645 loss_D_fake: 0.0471 loss_G: 3.7880\n",
      "Epoch 13 [300/469] loss_D_real: 0.0148 loss_D_fake: 0.0137 loss_G: 4.8618\n",
      "Epoch 13 [400/469] loss_D_real: 1.4325 loss_D_fake: 0.0100 loss_G: 1.5519\n",
      "Epoch 14 [0/469] loss_D_real: 0.0716 loss_D_fake: 0.8606 loss_G: 4.0674\n",
      "Epoch 14 [100/469] loss_D_real: 0.1246 loss_D_fake: 0.4830 loss_G: 2.8493\n",
      "Epoch 14 [200/469] loss_D_real: 0.0364 loss_D_fake: 0.0124 loss_G: 4.6105\n",
      "Epoch 14 [300/469] loss_D_real: 0.0149 loss_D_fake: 0.0215 loss_G: 5.1697\n",
      "Epoch 14 [400/469] loss_D_real: 0.3784 loss_D_fake: 0.1790 loss_G: 1.8381\n",
      "Epoch 15 [0/469] loss_D_real: 0.2921 loss_D_fake: 0.2039 loss_G: 1.7609\n",
      "Epoch 15 [100/469] loss_D_real: 0.0900 loss_D_fake: 0.3291 loss_G: 5.4924\n",
      "Epoch 15 [200/469] loss_D_real: 0.2145 loss_D_fake: 0.0485 loss_G: 2.9240\n",
      "Epoch 15 [300/469] loss_D_real: 0.1266 loss_D_fake: 0.1421 loss_G: 3.1791\n",
      "Epoch 15 [400/469] loss_D_real: 0.0595 loss_D_fake: 0.3525 loss_G: 4.3424\n",
      "Epoch 16 [0/469] loss_D_real: 0.0122 loss_D_fake: 0.0136 loss_G: 5.2031\n",
      "Epoch 16 [100/469] loss_D_real: 0.5867 loss_D_fake: 0.3461 loss_G: 1.2794\n",
      "Epoch 16 [200/469] loss_D_real: 0.2633 loss_D_fake: 0.0375 loss_G: 1.4831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 [300/469] loss_D_real: 0.0289 loss_D_fake: 0.7986 loss_G: 6.3119\n",
      "Epoch 16 [400/469] loss_D_real: 0.0426 loss_D_fake: 0.0280 loss_G: 4.5282\n",
      "Epoch 17 [0/469] loss_D_real: 0.0137 loss_D_fake: 0.0197 loss_G: 4.7820\n",
      "Epoch 17 [100/469] loss_D_real: 0.1132 loss_D_fake: 0.0396 loss_G: 2.8680\n",
      "Epoch 17 [200/469] loss_D_real: 0.0989 loss_D_fake: 0.0134 loss_G: 2.8161\n",
      "Epoch 17 [300/469] loss_D_real: 0.2646 loss_D_fake: 0.1632 loss_G: 1.8052\n",
      "Epoch 17 [400/469] loss_D_real: 0.0246 loss_D_fake: 0.0317 loss_G: 4.5901\n",
      "Epoch 18 [0/469] loss_D_real: 0.2348 loss_D_fake: 0.1100 loss_G: 2.4900\n",
      "Epoch 18 [100/469] loss_D_real: 0.0135 loss_D_fake: 0.0229 loss_G: 4.9680\n",
      "Epoch 18 [200/469] loss_D_real: 0.0236 loss_D_fake: 0.0022 loss_G: 5.5279\n",
      "Epoch 18 [300/469] loss_D_real: 0.2818 loss_D_fake: 0.0260 loss_G: 2.7689\n",
      "Epoch 18 [400/469] loss_D_real: 0.0038 loss_D_fake: 1.7457 loss_G: 6.2819\n",
      "Epoch 19 [0/469] loss_D_real: 0.2386 loss_D_fake: 0.8739 loss_G: 3.5278\n",
      "Epoch 19 [100/469] loss_D_real: 1.2476 loss_D_fake: 0.1087 loss_G: 0.9802\n",
      "Epoch 19 [200/469] loss_D_real: 0.0241 loss_D_fake: 0.0182 loss_G: 4.2619\n",
      "Epoch 19 [300/469] loss_D_real: 0.3029 loss_D_fake: 0.0839 loss_G: 2.1272\n",
      "Epoch 19 [400/469] loss_D_real: 0.0201 loss_D_fake: 0.0118 loss_G: 5.1081\n",
      "Epoch 20 [0/469] loss_D_real: 0.0111 loss_D_fake: 0.0188 loss_G: 4.7829\n",
      "Epoch 20 [100/469] loss_D_real: 0.1673 loss_D_fake: 2.0020 loss_G: 2.1949\n",
      "Epoch 20 [200/469] loss_D_real: 0.1675 loss_D_fake: 0.0502 loss_G: 2.5206\n",
      "Epoch 20 [300/469] loss_D_real: 0.0011 loss_D_fake: 3.9688 loss_G: 5.2386\n",
      "Epoch 20 [400/469] loss_D_real: 0.3168 loss_D_fake: 0.1161 loss_G: 2.5495\n",
      "Epoch 21 [0/469] loss_D_real: 0.1409 loss_D_fake: 0.9294 loss_G: 3.9387\n",
      "Epoch 21 [100/469] loss_D_real: 0.0250 loss_D_fake: 0.0408 loss_G: 4.8405\n",
      "Epoch 21 [200/469] loss_D_real: 0.0551 loss_D_fake: 0.0095 loss_G: 4.5025\n",
      "Epoch 21 [300/469] loss_D_real: 0.0165 loss_D_fake: 0.0088 loss_G: 4.7379\n",
      "Epoch 21 [400/469] loss_D_real: 0.1893 loss_D_fake: 0.4512 loss_G: 2.1369\n",
      "Epoch 22 [0/469] loss_D_real: 0.0641 loss_D_fake: 0.2854 loss_G: 3.3780\n",
      "Epoch 22 [100/469] loss_D_real: 0.4083 loss_D_fake: 0.1738 loss_G: 2.5096\n",
      "Epoch 22 [200/469] loss_D_real: 0.0883 loss_D_fake: 0.4249 loss_G: 4.1051\n",
      "Epoch 22 [300/469] loss_D_real: 0.0172 loss_D_fake: 0.0299 loss_G: 4.6408\n",
      "Epoch 22 [400/469] loss_D_real: 0.5266 loss_D_fake: 0.6915 loss_G: 0.8003\n",
      "Epoch 23 [0/469] loss_D_real: 0.0050 loss_D_fake: 1.1110 loss_G: 8.7681\n",
      "Epoch 23 [100/469] loss_D_real: 0.3639 loss_D_fake: 0.2513 loss_G: 1.5360\n",
      "Epoch 23 [200/469] loss_D_real: 0.0640 loss_D_fake: 0.2560 loss_G: 3.4794\n",
      "Epoch 23 [300/469] loss_D_real: 0.0406 loss_D_fake: 0.0361 loss_G: 3.8467\n",
      "Epoch 23 [400/469] loss_D_real: 0.0090 loss_D_fake: 0.0102 loss_G: 5.1005\n",
      "Epoch 24 [0/469] loss_D_real: 0.0112 loss_D_fake: 0.0099 loss_G: 5.1822\n",
      "Epoch 24 [100/469] loss_D_real: 0.7785 loss_D_fake: 0.0187 loss_G: 0.7586\n",
      "Epoch 24 [200/469] loss_D_real: 0.0295 loss_D_fake: 0.0314 loss_G: 4.3870\n",
      "Epoch 24 [300/469] loss_D_real: 0.0339 loss_D_fake: 0.0354 loss_G: 4.0300\n",
      "Epoch 24 [400/469] loss_D_real: 0.0117 loss_D_fake: 0.0079 loss_G: 5.3803\n"
     ]
    }
   ],
   "source": [
    "utils.clear_folder(OUT_PATH) #empty or create the output folder\n",
    "print(\"Logging to {}\\n\".format(LOG_FILE))\n",
    "sys.stdout = utils.StdOut(LOG_FILE)\n",
    "CUDA = CUDA and torch.cuda.is_available()\n",
    "print(\"PyTorch version: {}\".format(torch.__version__))\n",
    "if CUDA:\n",
    "    print(\"CUDA version: {}\\n\".format(torch.version.cuda))\n",
    "if seed is None:\n",
    "    seed = np.random.randint(1, 10000)\n",
    "print(\"Random Seed: \", seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if CUDA:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "cudnn.benchmark = True #tells cuda to choose best set of algo for the model if input data is fixed otherwise. best alog at each iteration.\n",
    "device = torch.device(\"cuda:0\" if CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c2a47a",
   "metadata": {
    "id": "86c2a47a"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # 1st layer\n",
    "            nn.ConvTranspose2d(Z_DIM, G_HIDDEN * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN * 8),\n",
    "            nn.ReLU(True),\n",
    "            # 2nd layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN * 8, G_HIDDEN * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN * 4),\n",
    "            nn.ReLU(True),\n",
    "            # 3rd layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN * 4, G_HIDDEN * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN * 2),\n",
    "            nn.ReLU(True),\n",
    "            # 4th layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN * 2, G_HIDDEN, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN),\n",
    "            nn.ReLU(True),\n",
    "            # output layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN, IMAGE_CHANNEL, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e96b90e7",
   "metadata": {
    "id": "e96b90e7"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c401bf45",
   "metadata": {
    "id": "c401bf45"
   },
   "outputs": [],
   "source": [
    "netG = Generator().to(device)\n",
    "netG.apply(weights_init)\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d70859d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d70859d",
    "outputId": "9d0b76fd-2d80-4c85-9339-4bff9cfb4be9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Generator"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c67a6157",
   "metadata": {
    "id": "c67a6157"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # 1st layer\n",
    "            nn.Conv2d(IMAGE_CHANNEL, D_HIDDEN, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 2nd layer\n",
    "            nn.Conv2d(D_HIDDEN, D_HIDDEN * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(D_HIDDEN * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 3rd layer\n",
    "            nn.Conv2d(D_HIDDEN * 2, D_HIDDEN * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(D_HIDDEN * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 4th layer\n",
    "            nn.Conv2d(D_HIDDEN * 4, D_HIDDEN * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(D_HIDDEN * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # output layer\n",
    "            nn.Conv2d(D_HIDDEN * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21216cb6",
   "metadata": {
    "id": "21216cb6"
   },
   "outputs": [],
   "source": [
    "netD = Discriminator().to(device)\n",
    "netD.apply(weights_init)\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efc8d8ee",
   "metadata": {
    "id": "efc8d8ee"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4e7bd6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4e7bd6c",
    "outputId": "ecb9531f-acd9-4bf6-85f2-b3764ea85067"
   },
   "outputs": [],
   "source": [
    "dataset = dset.MNIST(root=DATA_PATH, download=True,\n",
    "                     transform=transforms.Compose([\n",
    "                     transforms.Resize(X_DIM),\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize((0.5,), (0.5,))\n",
    "                     ]))\n",
    "assert dataset\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "522b0bf0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "522b0bf0",
    "outputId": "c288589e-e948-47b9-d207-dcc96d932445"
   },
   "outputs": [],
   "source": [
    "viz_noise = torch.randn(BATCH_SIZE, Z_DIM, 1, 1, device=device)\n",
    "for epoch in range(EPOCH_NUM):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        x_real = data[0].to(device)\n",
    "        real_label = torch.full((x_real.size(0),), REAL_LABEL, device=device)\n",
    "        fake_label = torch.full((x_real.size(0),), FAKE_LABEL, device=device)\n",
    "\n",
    "        # Update D with real data\n",
    "        netD.zero_grad()\n",
    "        y_real = netD(x_real)\n",
    "        loss_D_real = criterion(y_real.float(), real_label.float())\n",
    "        loss_D_real.backward()\n",
    "\n",
    "        # Update D with fake data\n",
    "        z_noise = torch.randn(x_real.size(0), Z_DIM, 1, 1, device=device)\n",
    "        x_fake = netG(z_noise)\n",
    "        y_fake = netD(x_fake.detach())\n",
    "        loss_D_fake = criterion(y_fake, fake_label.float())\n",
    "        loss_D_fake.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Update G with fake data\n",
    "        netG.zero_grad()\n",
    "        y_fake_r = netD(x_fake)\n",
    "        loss_G = criterion(y_fake_r, real_label.float())\n",
    "        loss_G.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch {} [{}/{}] loss_D_real: {:.4f} loss_D_fake: {:.4f} loss_G: {:.4f}'.format(\n",
    "                epoch, i, len(dataloader),\n",
    "                loss_D_real.mean().item(),\n",
    "                loss_D_fake.mean().item(),\n",
    "                loss_G.mean().item()\n",
    "            ))\n",
    "            vutils.save_image(x_real, os.path.join(OUT_PATH, 'real_samples.png'), normalize=True)\n",
    "            with torch.no_grad():\n",
    "                viz_sample = netG(viz_noise)\n",
    "                vutils.save_image(viz_sample, os.path.join(OUT_PATH, 'fake_samples_{}.png'.format(epoch)), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2b4a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(netG.state_dict(), os.path.join(OUT_PATH, 'netG_{}.pth'.format(epoch)))\n",
    "torch.save(netD.state_dict(), os.path.join(OUT_PATH, 'netD_{}.pth'.format(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ae579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d3c837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5340d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bd1b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b567e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9271f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cdaa3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10657f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189388bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0271a97e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c3b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0e2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763ebb3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55fd54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2100753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39c07d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bc8eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e082d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd14dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
